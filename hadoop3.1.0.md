## 新特性
- YARN 原生支持 GPU（详见 YARN-6223）
- YARN 原生支持 FPGA（详见 YARN-5983）
- 支持原生的 YARN 服务（详见 YARN-5079 / YARN-4793 / YARN-4757 / YARN-6419）
- YARN 新的调度放置策略
- 支持 docker container
- 容量调度（Capacity Scheduler）：支持在执行队列映射时自动创建叶队列（详见 YARN-7117）
- 允许将存储在 HDFS 之外的数据映射到 HDFS 并从 HDFS 进行寻址。

## YARN 服务
### 概述
  本阶段的目标是简化并且原生支持yarn的服务。
  本次提出新的jira的目的是：调研项目中已经实现的功能（yarn-896中已经提出yarn的常驻服务需求）；明确接下来具体的目标；聚焦896等需要高层框架实现的功能，探讨是否能整合到yarn平台中。
  
### 已有成果
  目前yarn局限于底层的resourcemanager api，以支持任何类型的app。MR等应用框架暴露了较高层次api供用户直接向yarn提交事务。Apache Slider也做了类似的事情。  
  将service引入yarn有以下几种方式：直接在yarn上使用支持运行已有服务的应用框架；改写已有的服务；使用yarn api，编写新的yarn应用来运行长服务。  
  方案1不需要写新代码，通过配置说明生成服务，并且隐藏了底层细节。新服务的开发者往往选择方案3，用复杂性来换取控制权和灵活性。  
  举一个具体实例说明当前的进展和未来可能的方向：HBase app通过Apache Slider服务框架运行在yarn上，该案例是方案1的一个实例。  
  HBase不能长时间运行在yarn上，由于am崩溃多次引起yarn标记任务为失败，或者运行一段时间后安全相关的令牌过期。故障切换的am不能连接至原来的container，由于am崩溃时yarn会kill所有container。日志聚合在app结束时生效，因此服务的日志也不能获取。一旦app开始运行，我们无法获取服务的结束点。服务趋向于与特定的节点有密切的联系，但由于yarn中缺少特定的调度特性，这几乎是不可能的。通过许多努力，我们已经解决了许多问题。  
  仍有一些服务使用者期待的特性我们无法做到。我们没有便捷的方法支持服务升级；当我们试图在同样的yarn集群中运行短app和服务时，我们没有优秀的调度模式。一旦我们在yarn上开始运行服务，监控服务的办法方面是缺失的，已有的度量框架是为短app而设计的，在度量采集、传递和长期存储方面，yarn的服务需自研发。另外在开发者方面，在yarn上引入服务也不是一项简单的体验，已有框架的api要么是太低层级（原生yarn）需要编写太多代码，要么是需要编写复杂的说明细则（说明式的框架）。打包和安装服务迫使开发者经历像传统tar包这种不标准的体验。  
  另外一些问题是yarn低层次api的副作用。像错误处理、配置管理这种功能在不同框架中多次实现。为了提供一种yarn服务的新面貌，我们应该引入一些常见功能以便yarn生态享受创新性的体验。
  
### 提案概况
#### 原生支持服务
1. 识别服务：处理资源抢占和container预约。有一些领域中服务的识别不仅是不可避免的而且是必须的，资源抢占与预约需要理解一个应用是否有长运行的container，并且根据结果做出决定。
2. 自动重启的container：长运行的container由于多种原因可能崩溃并且需要重启，对服务来说，yarn需要基于策略自动重启container。
3. 应用升级后的重用分配：为支持升级，我们需要让应用重用相同的yarn资源分配。
4. 重新配置或升级后资源的重新本地化：一旦服务的container启动，需要用新的或者升级之后的实例重新初始化。yarn需要允许应用重用已经存在的分配策略，但是用修改后的本地资源重启container。
5. 允许动态配置：截止目前，我们总是让app驱动他们的配置。动态配置是app的一个烦恼点。我们需要更好的方式来将重要的信息（比如日志的路径）传递至container。允许动态传递运行时配置对app是有用的，另外一些像服务的终端信息这些动态配置也是需要的
6. 网络资源分配：一旦开始在同一个节点上运行同一个app的多个实例，yarn需要协调服务所需的网络资源的共享，这意味着需要分配网络地址或者是端口。
7. 调度：yarn896涵盖了一些调度特性，这些调度特性对短运行的app和服务都有用。我们需要聚焦于一条基线，没有这个，在yarn上运行服务是非常困难的：在队列存在的情况下更新队列模型，gangscheduling，container规模的可扩展，资源的委托，系统服务的自产生。
8. 资源配置：随着资源类型（磁盘、网络）的增加，指定app需求的资源变得越来越困难。不合适的资源配置会导致资源浪费。yarn需要有更简单的方式建模资源需求：resource-profiles可用app使用。
9. 服务的存储需求：yarn给app分配本地路径以满足他们本地存储的需求。许多服务是由状态的并且需要yarn的帮助。这会影响这些数据的生命周期，并且在container重启期间我们如何处理分配和container标识等事情。关于磁盘使用的较新的隔离需求给服务以长生命周期的特性，并且更好的处理磁盘和资源的能力。
10. 服务注册：yarn服务注册为app注册endpoint以及客户端发现他们提供了便利条件。我们需要完成现有的工作：仍有一些重要的工作需要处理。我们也需要简化注册条款的途径：我们提出了一种解决方案，通过DNS这种更加广泛使用的和通用的发现机制来暴露注册信息。最终，解决am发现旧container的问题能够分享一些帮助我们扩大注册者-订阅者规模的基础框架。

#### 简化服务支持
1. 框架：由于yarn使用低层次的api以支持任何类型的应用，mr等框架最终暴露了更高层次的api使在yarn上构建app变得更加便利。在服务方面，slider做了类似的事情。我们当前的关注点是简化服务，是时候看一下我们怎样让yarn良好的支持服务。我们提议同化客户端、am等框架现有组件来实现这一目的。
2. api层：除了在yarn内部创建关键的block，我们也应该简化用户面对创建服务的事务。这里，基于Slider创建的HBase等服务教我们怎样简化api以创建我们想要的服务。我们有由rest接口支撑的简化的服务 api层的原型，我们希望这可以贡献我们这个提案的一部分。这一层充当在yarn上通过slider用于创建和生命周期管理的单点。
3. 打包：支持新的打包模式，比如yarn中的docker。我们可以利用不同container格式的简化版的打包来简化服务支持。yarn应该支持容器化格式的服务定义作为原生打包规则：nm应该识别container概念作为原生实例，接着在本地化过程中与概念库中的交互，并且管理本地化实例的生命周期。另外，为了让docker无缝集成，yarn应该支持docker生态的api。
4. 监控：yarn支持监控container的资源使用，他也从底层os上继承了基本的container生命周期监控。除了基本的资源和生命周期监控，现在我们没有任何机制监控container的活动，这对于服务来说是重要的需求。历史上，我们总是作为应用开发者的任务，但是作为yarn支持服务的基本需求，这将简化服务和应用开发者的工作。
5. 度量：yarn2928中，我们构建了一个应用的度量框架的关键部分，但是这只针对在合理周期内结束的应用有效。服务的度量采集有不同的需求：我么可以利用yarn2928大部分的框架，或者提供一个原生的方式将用户将他们的服务导入已有的度量系统中，比如Ganglia。

### 深入论述
#### 现有成果
1. 长运行app的am的容错：之前am出错后，只能重试一定的次数，因为不能恢复的错误尝试太多次没有意义，太多次之后yarn杀掉am（最大重试次数的概念，默认是2）。后来yarn611提出了正常工作时间窗口的概念，这次崩溃之后，看上次崩溃是不是落在这个窗口之外，如果是的话，本地崩溃不能算失败，应该重启（即只有频繁的崩溃才算是失败，否则需要重启）。另外还有“am错误应与硬件错误或yarn错误区别，不讲它计入重试计数”“抢占amcontainer不计入am错误次数”。
2. 工作保留am重启：yarn1489中告诉rm不要kill之前applicationattempt中所有的container，新applicationattempt知道之前container运行在哪里。
3. 初步处理长运行服务的日志：yarn2443
4. 初步的服务注册：yarn913添加服务注册层，允许yarn上运行的服务注册他们的endpoint。
5. 通过节点标签的container的放置策略：yarn796和3214允许为节点指定标签，并且允许app通过指定他们的需求。引入了分区的概念（节点标签对队列容量有影响），他们是怎么样共享的，引申至其他类型的限制。
6. 滚动升级与工作保留的rm和nm重启：
#### 原生支持服务
需要什么、怎么实现  
这些功能可能不是必须的，但是尽管如此是有需求的，避免在每个框架中都重复实现。
1. 识别服务：  
现在yarn的抢占资源通过kill container实现。显然抢占长运行container对app来说是困难并且代价大的，对许多常驻应用，通过kill来抢占对他们来说是不能容忍的。**抢占意味着调度器应该避免将借来的资源分配给长运行的container。**  
另一方面，现在，当无法用空闲资源满足一个container时，调度器为其预约。当为长运行服务的container预约时，调度器不应该将这一预约放置在同一节点的其他服务之后，否则这一预约可能永远无法满足。**抢占和预约逻辑应该理解一个应用是否是长运行的，然后再做决定。**  
**已有的jira yarn1039为yarn的资源请求添加一个参数以标识是常驻的，这一提案是处理服务container的一些特殊识别。选项在于是一个布尔标识还是整个生命周期都存在的长代表，我认为二者都需要。**
2. container自动重启：  
现在，当一个container停止，nm假设container分配也失效了，然后汇报给rm，rm释放这一分配。对服务的container来说，很多情况下这是没必要的。长运行的container可能由于很多原因而退出，然后需要重启，强制他们经历整个调度周期、资源本地化是没有必要的。**对服务来说，最好是让NodeManager自动重启container，这有点像系统层面的初始化脚本和守护进程。**  
类似于处理yarn上的am重启，我们需要针对app的策略，自动重启container，但是如果container短时间内停止过多次，应该限制这些重启。yarn3998“添加重试次数，当启动失败，让nm重新分配container”看起来与这个需求很类型。  
3. 应用升级的分配重用  
服务运行在yarn上后，container分配周期生效，当container退出后，yarn收回资源。在升级期间，系统中运行着其他的应用，释放然后取回当前服务分配到的资源是很难做到的。  
我们需要一种优雅的方式让app重用相同的资源的分配，这通过将分配周期和进程周期去耦合来实现。  
yarn1040将container生命周期从进程中解连接，将多个进程在同一个常驻container中执行。这里我们需要做两件事：**ApplicationMaster应该使用相同的container分配，将不同的startContainer请求发送至NodeManager**；**为了支持applicationmaster自身的升级，客户端应该能通知yarn使用相同的分配、使用新的信息重启am。**
4. 重新配置和升级后资源的重新本地化  
一旦服务的container启动，有了新的配置文件后需要重新初始化，和前节提到的一样，没有yarn的帮助这是很困难的。  
**yarn应该允许app重用已经存在的分配，但是用修改过的本地资源重启container。**  
**改变NodeManager的生命周期以保持本地化自始至终都在进行，这对服务重新配置这一目的有用。进一步，通过持续化的本地化，让container let down并且在运行期间使用新的jar包，资源。**
5. 支持动态配置
服务由支持配置的需求。目前为止，我们让应用程序自己驱动配置。这对静态配置和不需要依赖环境的情况下是有效的，但是为了简化服务的生命周期，我们需要动态配置。
  - 需要更好的方式将重要的信息传递给containers，比如container的资源大小，本地路径和日志路径。
  - 处理动态配置：service依赖动态配置，现在依赖配置文件的app需要自己从NodeManager获取信息然后生成文件。
6. 网络资源分配
服务需要使用网络资源，yarn需要协调网络资源。应用可以依赖固定在特定host上的特定组件，或者限制在一个已知的端口上而不管运行在哪个host上。有两种
  
